{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. YOLO RarePlanes Model Scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This last notebook converts the ground truth annotations to the bounding box format whcih YOLO creates in order to compare them with the predictions. Then, precision, recall, and f1 are calculated by class and as a whole. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/solaris/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ubuntu/anaconda3/envs/solaris/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ubuntu/anaconda3/envs/solaris/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ubuntu/anaconda3/envs/solaris/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ubuntu/anaconda3/envs/solaris/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ubuntu/anaconda3/envs/solaris/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from shapely.geometry import box\n",
    "import argparse\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from solaris.eval.iou import calculate_iou"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Ground Truth to Bounding Boxes\n",
    "\n",
    "The following scripts take the geojson ground truths for the test set and convert them to bounding boxes. Then, in the two cells, the same custom classes are created in the ground truth. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66/66 [00:03<00:00, 16.67it/s]\n"
     ]
    }
   ],
   "source": [
    "input_folder = \"/home/ubuntu/src/yolo_planes/wdata/test/geojson_aircraft\"\n",
    "output_folder = \"/home/ubuntu/src/yolo_planes/wdata/test/geojson_aircraft_bbox\"\n",
    "os.makedirs(output_folder,exist_ok=True)\n",
    "os.chdir(input_folder)\n",
    "geojsons = glob.glob(\"*.geojson\")\n",
    "for geojson in tqdm(geojsons):\n",
    "    gdf = gpd.read_file(geojson)\n",
    "    box_geoms= []\n",
    "    for _, row in gdf.iterrows():\n",
    "        x = row.geometry.bounds\n",
    "        bbox = box(x[0], x[1], x[2], x[3])\n",
    "        box_geoms.append(bbox)\n",
    "    gdf['box_geom'] = box_geoms\n",
    "    gdf = gdf.drop('geometry',axis=1)\n",
    "    gdf = gpd.GeoDataFrame(gdf, geometry='box_geom')\n",
    "    out_name=os.path.join(output_folder, geojson)\n",
    "    gdf.to_file(out_name, driver='GeoJSON', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_unique_index(df, by):\n",
    "    return df.groupby(by).size().reset_index().rename(columns={0: 'count'})\n",
    "\n",
    "def create_custom_classes(all_annotations_geojson, geojson_dir, output_path, category_attributes):\n",
    "    \"\"\" parse the geojson files and create custom classes based upon\n",
    "    unique variatons of the RarePlanes attributes.\n",
    "        -all_annotations_geojson (str): The path to the\n",
    "        `RarePlanes_Public_All_Annotations.geojson` file.\n",
    "        - geojson_dir (str): directory containing the geojson files\n",
    "        for individual images or tiles\n",
    "        - output_path (str): directory to output the customized geojsons. Need to provide the absolute path.\n",
    "        - category_attributes (list): A list of attributes to combine\n",
    "        to create a custom class.  Choose any combintaion of the following:\n",
    "        ['role','num_engines', 'propulsion', 'canards', 'num_tail_fins',\n",
    "       'wing_position', 'wing_type', 'faa_wingspan_class']\n",
    "    :returns\n",
    "        - new geojsons with a custom_id for each combination of unique\n",
    "        attributes.\n",
    "        -A lookup table for each classes custom_id.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    gdf = gpd.read_file(all_annotations_geojson)\n",
    "    lookup_gdf = count_unique_index(gdf, category_attributes)\n",
    "    lookup_gdf['custom_id'] = list(range(0, len(lookup_gdf)))\n",
    "    lookup_gdf.drop(columns=['count'], inplace=True)\n",
    "    lookup_gdf.to_csv(os.path.join(output_path, \"custom_class_lookup.csv\"))\n",
    "    os.chdir(geojson_dir)\n",
    "    geojsons = glob.glob(\"*.geojson\")\n",
    "    for geojson in tqdm(geojsons):\n",
    "        gdf = gpd.read_file(geojson)\n",
    "        gdf = pd.merge(gdf, lookup_gdf, on=category_attributes, how='left')\n",
    "        gdf[\"custom_id\"] = pd.to_numeric(gdf[\"custom_id\"], downcast='float')\n",
    "        gdf.to_file(os.path.join(output_path, geojson), driver=\"GeoJSON\", encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66/66 [00:03<00:00, 18.73it/s]\n"
     ]
    }
   ],
   "source": [
    "all_annotations_geojson = '/home/ubuntu/src/yolo_planes/wdata/RarePlanes_Public_All_Annotations.geojson'\n",
    "geojson_dir_test = '/home/ubuntu/src/yolo_planes/wdata/test/geojson_aircraft_bbox'\n",
    "\n",
    "output_path_test_one = '/home/ubuntu/src/yolo_planes/wdata/test/yolo_class_one_truth_bbox'\n",
    "\n",
    "class_one = ['num_engines', 'propulsion']\n",
    "\n",
    "create_custom_classes(all_annotations_geojson, geojson_dir_test, output_path_test_one, class_one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_score_by_class(ious, threshold=0.5):\n",
    "    \"\"\" for a list of object ious by class, test if they are a counted as a\n",
    "    positive or a negative.\n",
    "    Arguments\n",
    "    ---------\n",
    "        ious : list of lists\n",
    "            A list containing individual lists of ious for eachobject class.\n",
    "        threshold : float\n",
    "            A value between 0.0 and 1.0 that determines the threshold for a true positve.\n",
    "    Returns\n",
    "    ---------\n",
    "        average_by_class : list\n",
    "            A list containing the ratio of true positives for each class\n",
    "    \"\"\"\n",
    "    binary_scoring_lists = []\n",
    "    for x in ious:\n",
    "        items = []\n",
    "        for i in x:\n",
    "            if i >= threshold:\n",
    "                items.append(1)\n",
    "            else:\n",
    "                items.append(0)\n",
    "        binary_scoring_lists.append(items)\n",
    "    average_by_class = []\n",
    "    for l in binary_scoring_lists:\n",
    "        average_by_class.append(np.nanmean(l))\n",
    "    return average_by_class\n",
    "\n",
    "def get_all_objects(proposal_polygons_dir, gt_polygons_dir,\n",
    "                    prediction_cat_attrib=\"class\", gt_cat_attrib='make',\n",
    "                    file_format=\"geojson\"):\n",
    "    \"\"\" Using the proposal and ground truth polygons, calculate the total.\n",
    "    Filenames of predictions and ground-truth must be identical.\n",
    "    unique classes present in each\n",
    "    Arguments\n",
    "    ---------\n",
    "        proposal_polygons_dir : str\n",
    "            The path that contains any model proposal polygons\n",
    "        gt_polygons_dir : str\n",
    "            The path that contains the ground truth polygons\n",
    "        prediction_cat_attrib : str\n",
    "            The column or attribute within the predictions that specifies\n",
    "            unique classes\n",
    "        gt_cat_attrib : str\n",
    "            The column or attribute within the ground truth that\n",
    "            specifies unique classes\n",
    "        file_format : str\n",
    "            The extension or file format for predictions\n",
    "    Returns\n",
    "    ---------\n",
    "            prop_objs : list\n",
    "                All unique objects that exist in the proposals\n",
    "            gt_obj : list\n",
    "                All unique objects that exist in the ground truth\n",
    "            all_objs : list\n",
    "                A union of the prop_objs and gt_objs lists\n",
    "    \"\"\"\n",
    "    objs = []\n",
    "    os.chdir(proposal_polygons_dir)\n",
    "    search = \"*\" + file_format\n",
    "    proposal_geojsons = glob.glob(search)\n",
    "    for geojson in (proposal_geojsons):\n",
    "        ground_truth_poly = os.path.join(gt_polygons_dir, geojson)\n",
    "        if os.path.exists(ground_truth_poly):\n",
    "            ground_truth_gdf = gpd.read_file(ground_truth_poly)\n",
    "            proposal_gdf = gpd.read_file(geojson)\n",
    "            for index, row in (proposal_gdf.iterrows()):\n",
    "                objs.append(row[str(prediction_cat_attrib)])\n",
    "    prop_objs = list(set(objs))\n",
    "    os.chdir(gt_polygons_dir)\n",
    "    search = \"*\" + file_format\n",
    "    objs = []\n",
    "    gt_geojsons = glob.glob(search)\n",
    "    for geojson in (gt_geojsons):\n",
    "        proposal_poly = os.path.join(proposal_polygons_dir, geojson)\n",
    "        if os.path.exists(proposal_poly):\n",
    "            proposal_gdf = gpd.read_file(proposal_poly)\n",
    "            ground_truth_gdf = gpd.read_file(geojson)\n",
    "            for index, row in (ground_truth_gdf.iterrows()):\n",
    "                objs.append(row[gt_cat_attrib])\n",
    "    gt_objs = list(set(objs))\n",
    "    all_objs = gt_objs + prop_objs\n",
    "    all_objs = list(set(all_objs))\n",
    "    return prop_objs, gt_objs, all_objs\n",
    "\n",
    "\n",
    "def precision_calc(proposal_polygons_dir, gt_polygons_dir,\n",
    "                   prediction_cat_attrib=\"class\", gt_cat_attrib='make',\n",
    "                   object_subset=[], threshold=0.5, file_format=\"geojson\"):\n",
    "    \"\"\" Using the proposal and ground truth polygons, calculate precision metrics.\n",
    "    Filenames of predictions and ground-truth must be identical.  Will only\n",
    "    calculate metric for classes that exist in the ground truth.\n",
    "    Arguments\n",
    "    ---------\n",
    "        proposal_polygons_dir : str\n",
    "            The path that contains any model proposal polygons\n",
    "        gt_polygons_dir : str\n",
    "            The path that contains the ground truth polygons\n",
    "        prediction_cat_attrib : str\n",
    "            The column or attribute within the predictions that specifies\n",
    "            unique classes\n",
    "        gt_cat_attrib : str\n",
    "            The column or attribute within the ground truth that\n",
    "            specifies unique classes\n",
    "        object_subset : list\n",
    "            A list or subset of the unique objects that are contained within the\n",
    "            ground truth polygons. If empty, this will be\n",
    "            auto-created using all classes that appear ground truth polygons.\n",
    "        threshold : float\n",
    "            A value between 0.0 and 1.0 that determines the IOU threshold for a\n",
    "            true positve.\n",
    "        file_format : str\n",
    "            The extension or file format for predictions\n",
    "    Returns\n",
    "    ---------\n",
    "        iou_holder : list of lists\n",
    "            An iou score for each object per class (precision specific)\n",
    "        precision_by_class : list\n",
    "            A list containing the precision score for each class\n",
    "        mPrecision : float\n",
    "            The mean precision score of precision_by_class\n",
    "    \"\"\"\n",
    "    ious = []\n",
    "    os.chdir(proposal_polygons_dir)\n",
    "    search = \"*\" + file_format\n",
    "    proposal_geojsons = glob.glob(search)\n",
    "    iou_holder = []\n",
    "    if len(object_subset) == 0:\n",
    "        prop_objs, object_subset, all_objs = get_all_objects(\n",
    "            proposal_polygons_dir, gt_polygons_dir,\n",
    "            prediction_cat_attrib=prediction_cat_attrib,\n",
    "            gt_cat_attrib=gt_cat_attrib, file_format=file_format)\n",
    "    for i in range(len(object_subset)):\n",
    "        iou_holder.append([])\n",
    "\n",
    "    for geojson in (proposal_geojsons):\n",
    "        ground_truth_poly = os.path.join(gt_polygons_dir, geojson)\n",
    "        if os.path.exists(ground_truth_poly):\n",
    "            ground_truth_gdf = gpd.read_file(ground_truth_poly)\n",
    "            proposal_gdf = gpd.read_file(geojson)\n",
    "            i = 0\n",
    "            for obj in object_subset:\n",
    "                proposal_gdf2 = proposal_gdf[proposal_gdf[prediction_cat_attrib] == obj]\n",
    "                for index, row in (proposal_gdf2.iterrows()):\n",
    "                    iou_GDF = calculate_iou(row.geometry, ground_truth_gdf)\n",
    "                    if 'iou_score' in iou_GDF.columns:\n",
    "                        iou = iou_GDF.iou_score.max()\n",
    "                        max_iou_row = iou_GDF.loc[iou_GDF['iou_score'].idxmax(axis=0, skipna=True)]\n",
    "                        id_1 = row[prediction_cat_attrib]\n",
    "                        id_2 = ground_truth_gdf.loc[max_iou_row.name][gt_cat_attrib]\n",
    "                        if id_1 == id_2:\n",
    "                            ious.append(iou)\n",
    "                            ground_truth_gdf.drop(max_iou_row.name, axis=0, inplace=True)\n",
    "                        else:\n",
    "                            iou = 0\n",
    "                            ious.append(iou)\n",
    "                    else:\n",
    "                        iou = 0\n",
    "                        ious.append(iou)\n",
    "                for item in ious:\n",
    "                    iou_holder[i].append(item)\n",
    "                ious = []\n",
    "                i += 1\n",
    "        else:\n",
    "            print(\"Warning- No ground truth for:\", geojson)\n",
    "            proposal_gdf = gpd.read_file(geojson)\n",
    "            i = 0\n",
    "\n",
    "            for obj in object_subset:\n",
    "                proposal_gdf2 = proposal_gdf[proposal_gdf[gt_cat_attrib] == obj]\n",
    "                for z in range(len(proposal_gdf2)):\n",
    "                    ious.append(0)\n",
    "                for item in ious:\n",
    "                    iou_holder[i].append(item)\n",
    "                i += 1\n",
    "                ious = []\n",
    "    precision_by_class = average_score_by_class(iou_holder, threshold=0.5)\n",
    "    precision_by_class = list(np.nan_to_num(precision_by_class))\n",
    "    mPrecision = np.nanmean(precision_by_class)\n",
    "    print(\"mPrecision:\", mPrecision)\n",
    "    return iou_holder, precision_by_class, mPrecision\n",
    "\n",
    "\n",
    "def recall_calc(proposal_polygons_dir, gt_polygons_dir,\n",
    "                prediction_cat_attrib=\"class\", gt_cat_attrib='make',\n",
    "                object_subset=[], threshold=0.5, file_format=\"geojson\"):\n",
    "    \"\"\" Using the proposal and ground truth polygons, calculate recall metrics.\n",
    "    Filenames of predictions and ground-truth must be identical. Will only\n",
    "    calculate metric for classes that exist in the ground truth.\n",
    "    Arguments\n",
    "    ---------\n",
    "        proposal_polygons_dir : str\n",
    "            The path that contains any model proposal polygons\n",
    "        gt_polygons_dir : str\n",
    "            The path that contains the ground truth polygons\n",
    "        prediction_cat_attrib : str\n",
    "            The column or attribute within the predictions that specifies\n",
    "            unique classes\n",
    "        gt_cat_attrib : str\n",
    "            The column or attribute within the ground truth that\n",
    "            specifies unique classes\n",
    "        object_subset : list\n",
    "            A list or subset of the unique objects that are contained within the\n",
    "            ground truth polygons. If empty, this will be\n",
    "            auto-created using all classes that appear ground truth polygons.\n",
    "        threshold : float\n",
    "            A value between 0.0 and 1.0 that determines the IOU threshold for a\n",
    "            true positve.\n",
    "        file_format : str\n",
    "            The extension or file format for predictions\n",
    "    Returns\n",
    "    ---------\n",
    "        iou_holder : list of lists\n",
    "            An iou score for each object per class (recall specific)\n",
    "        recall_by_class : list\n",
    "            A list containing the recall score for each class\n",
    "        mRecall : float\n",
    "            The mean recall score of recall_by_class\n",
    "    \"\"\"\n",
    "    ious = []\n",
    "    os.chdir(gt_polygons_dir)\n",
    "    search = \"*\" + file_format\n",
    "    gt_geojsons = glob.glob(search)\n",
    "    iou_holder = []\n",
    "    if len(object_subset) == 0:\n",
    "        prop_objs, object_subset, all_objs = get_all_objects(\n",
    "            proposal_polygons_dir, gt_polygons_dir,\n",
    "            prediction_cat_attrib=prediction_cat_attrib,\n",
    "            gt_cat_attrib=gt_cat_attrib, file_format=file_format)\n",
    "    for i in range(len(object_subset)):\n",
    "        iou_holder.append([])\n",
    "    for geojson in (gt_geojsons):\n",
    "        proposal_poly = os.path.join(proposal_polygons_dir, geojson)\n",
    "        if os.path.exists(proposal_poly):\n",
    "            proposal_gdf = gpd.read_file(proposal_poly)\n",
    "            ground_truth_gdf = gpd.read_file(geojson)\n",
    "            i = 0\n",
    "            for obj in object_subset:\n",
    "                ground_truth_gdf2 = ground_truth_gdf[ground_truth_gdf[gt_cat_attrib] == obj]\n",
    "                for index, row in (ground_truth_gdf2.iterrows()):\n",
    "                    iou_GDF = calculate_iou(row.geometry, proposal_gdf)\n",
    "                    if 'iou_score' in iou_GDF.columns:\n",
    "                        iou = iou_GDF.iou_score.max()\n",
    "                        max_iou_row = iou_GDF.loc[iou_GDF['iou_score'].idxmax(axis=0, skipna=True)]\n",
    "                        id_1 = row[gt_cat_attrib]\n",
    "                        id_2 = proposal_gdf.loc[max_iou_row.name][prediction_cat_attrib]\n",
    "                        if id_1 == id_2:\n",
    "                            ious.append(iou)\n",
    "                            proposal_gdf.drop(max_iou_row.name, axis=0, inplace=True)\n",
    "                        else:\n",
    "                            iou = 0\n",
    "                            ious.append(iou)\n",
    "                    else:\n",
    "                        iou = 0\n",
    "                        ious.append(iou)\n",
    "                for item in ious:\n",
    "                    iou_holder[i].append(item)\n",
    "                i += 1\n",
    "                ious = []\n",
    "        else:\n",
    "            ground_truth_gdf = gpd.read_file(geojson)\n",
    "            i = 0\n",
    "            for obj in object_subset:\n",
    "                ground_truth_gdf2 = ground_truth_gdf[ground_truth_gdf[gt_cat_attrib] == obj]\n",
    "                for z in range(len(ground_truth_gdf2)):\n",
    "                    ious.append(0)\n",
    "                for item in ious:\n",
    "                    iou_holder[i].append(item)\n",
    "                i += 1\n",
    "                ious = []\n",
    "\n",
    "    recall_by_class = average_score_by_class(iou_holder, threshold=0.5)\n",
    "    recall_by_class = list(np.nan_to_num(recall_by_class))\n",
    "    mRecall = np.nanmean(recall_by_class)\n",
    "    print(\"mRecall:\", mRecall)\n",
    "    return iou_holder, recall_by_class, mRecall\n",
    "\n",
    "\n",
    "def mF1(proposal_polygons_dir, gt_polygons_dir, prediction_cat_attrib=\"class\",\n",
    "        gt_cat_attrib='make', object_subset=[], threshold=0.5,\n",
    "        file_format=\"geojson\", all_outputs=False):\n",
    "    \"\"\" Using the proposal and ground truth polygons, calculate F1 and mF1\n",
    "    metrics. Filenames of predictions and ground-truth must be identical.  Will\n",
    "    only calculate metric for classes that exist in the ground truth.\n",
    "    Arguments\n",
    "    ---------\n",
    "        proposal_polygons_dir : str\n",
    "            The path that contains any model proposal polygons\n",
    "        gt_polygons_dir : str\n",
    "            The path that contains the ground truth polygons\n",
    "        prediction_cat_attrib : str\n",
    "            The column or attribute within the predictions that specifies\n",
    "            unique classes\n",
    "        gt_cat_attrib : str\n",
    "            The column or attribute within the ground truth that\n",
    "            specifies unique classes\n",
    "        object_subset : list\n",
    "            A list or subset of the unique objects that are contained within the\n",
    "            proposal and ground truth polygons. If empty, this will be\n",
    "            auto-created using all classes that appear in the proposal and\n",
    "            ground truth polygons.\n",
    "        threshold : float\n",
    "            A value between 0.0 and 1.0 that determines the IOU threshold for a\n",
    "            true positve.\n",
    "        file_format : str\n",
    "            The extension or file format for predictions\n",
    "        all_outputs : bool\n",
    "            `True` or `False`.  If `True` returns an expanded output.\n",
    "    Returns\n",
    "    ---------\n",
    "        if all_outputs is `True`:\n",
    "            mF1 : float\n",
    "                The mean F1 score of f1s_by_class\n",
    "            f1s_by_class : list\n",
    "                A list containing the f1 score for each class\n",
    "            precision_iou_by_obj : list of lists\n",
    "                An iou score for each object per class (precision specific)\n",
    "            precision_by_class : list\n",
    "                A list containing the precision score for each class\n",
    "            mPrecision : float\n",
    "                The mean precision score of precision_by_class\n",
    "            recall_iou_by_obj : list of lists\n",
    "                An iou score for each object per class (recall specific)\n",
    "            recall_by_class : list\n",
    "                A list containing the recall score for each class\n",
    "            mRecall : float\n",
    "                The mean recall score of recall_by_class\n",
    "            object_subset : list\n",
    "                All unique objects that exist in the ground truth polygons\n",
    "            prop_objs : list\n",
    "                All unique objects that exist in the proposal polygons\n",
    "            all_objs : list\n",
    "                All unique objects that exist in both the proposal and ground\n",
    "                truth polygons\n",
    "        if all_outputs is `False`:\n",
    "            mF1_score : float\n",
    "                The mean F1 score of f1s_by_class (only calculated for ground\n",
    "                ground truth classes)\n",
    "            f1s_by_class : list\n",
    "                A list containing the f1 score for each class\n",
    "    \"\"\"\n",
    "    if len(object_subset) == 0:\n",
    "        print(\"getting unique objects...\")\n",
    "        prop_objs, object_subset, all_objs = get_all_objects(\n",
    "            proposal_polygons_dir, gt_polygons_dir,\n",
    "            prediction_cat_attrib=prediction_cat_attrib,\n",
    "            gt_cat_attrib=gt_cat_attrib, file_format=file_format)\n",
    "    print(\"calculating recall...\")\n",
    "    recall_iou_by_obj, recall_by_class, mRecall = recall_calc(\n",
    "        proposal_polygons_dir, gt_polygons_dir,\n",
    "        prediction_cat_attrib=prediction_cat_attrib,\n",
    "        gt_cat_attrib=gt_cat_attrib, object_subset=object_subset,\n",
    "        threshold=threshold, file_format=file_format)\n",
    "    print(\"calculating precision...\")\n",
    "    precision_iou_by_obj, precision_by_class, mPrecision = precision_calc(\n",
    "        proposal_polygons_dir, gt_polygons_dir,\n",
    "        prediction_cat_attrib=prediction_cat_attrib,\n",
    "        gt_cat_attrib=gt_cat_attrib, object_subset=object_subset,\n",
    "        threshold=threshold, file_format=file_format)\n",
    "    print(\"\")\n",
    "    print(\"calculating F1 scores...\")\n",
    "    f1s_by_class = []\n",
    "    for recall, precision in zip(recall_by_class, precision_by_class):\n",
    "        f1 = 2 * precision * recall / (precision + recall)\n",
    "        f1 = np.nan_to_num(f1)\n",
    "        f1s_by_class.append(f1)\n",
    "    mF1_score = np.nanmean(f1s_by_class)\n",
    "    print(\"mF1:\", mF1_score)\n",
    "    if all_outputs is True:\n",
    "        return mF1_score, f1s_by_class, precision_iou_by_obj, precision_by_class, mPrecision, recall_iou_by_obj, recall_by_class, mRecall, object_subset, prop_objs, all_objs\n",
    "    else:\n",
    "        return mF1_score, f1s_by_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n",
    "The following cells execute the scoring of the predicitons vs the ground truth. The first cell outputs total recall, precision, and F1, while the second cell outputs the lookup table and now includes the class by class recall, precision, and F1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting unique objects...\n",
      "calculating recall...\n",
      "mRecall: 0.6511768568429169\n",
      "calculating precision...\n",
      "mPrecision: 0.7047816872010533\n",
      "\n",
      "calculating F1 scores...\n",
      "mF1: 0.6732098637317354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/solaris/lib/python3.7/site-packages/ipykernel_launcher.py:26: RuntimeWarning: Mean of empty slice\n",
      "/home/ubuntu/anaconda3/envs/solaris/lib/python3.7/site-packages/ipykernel_launcher.py:364: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    }
   ],
   "source": [
    "proposal_polygons_dir =\"/home/ubuntu/src/yolo_planes/yolov5/inference/class_one_out/bounding_boxes\"\n",
    "gt_polygons_dir = \"/home/ubuntu/src/yolo_planes/wdata/test/yolo_class_one_truth_bbox\"\n",
    "mF1, f1s_by_class, precision_iou_by_obj, precision_by_class, mPrecision, recall_iou_by_obj, recall_by_class, mRecall, object_subset, prop_objs, all_objs = mF1(proposal_polygons_dir, gt_polygons_dir, prediction_cat_attrib=\"class_id\", gt_cat_attrib='custom_id', object_subset=[], all_outputs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   num_engines propulsion  recall_by_class  precision_by_class  f1s_by_class\n",
      "0            0  unpowered         0.729730            0.729730      0.729730\n",
      "1            1        jet         0.250000            0.250000      0.250000\n",
      "2            1  propeller         0.933941            0.933941      0.933941\n",
      "3            2        jet         0.978015            0.978015      0.978015\n",
      "4            2  propeller         0.885305            0.885305      0.885305\n",
      "5            3        jet         0.000000            0.000000      0.000000\n",
      "6            4        jet         0.690000            0.690000      0.690000\n",
      "7            4  propeller         0.742424            0.742424      0.742424\n"
     ]
    }
   ],
   "source": [
    "lookup_table = \"/home/ubuntu/src/yolo_planes/geojsons_test/yolo_class_one/custom_class_lookup.csv\"\n",
    "lookup_table = pd.read_csv(lookup_table)\n",
    "lookup_table = lookup_table.drop('custom_id',1)\n",
    "lookup_table.drop(lookup_table.columns[lookup_table.columns.str.contains('unnamed',case = False)],axis = 1, inplace = True)\n",
    "lookup_table['recall_by_class'] = recall_by_class\n",
    "lookup_table.set_index('recall_by_class')\n",
    "lookup_table['precision_by_class'] = recall_by_class\n",
    "lookup_table.set_index('precision_by_class')\n",
    "lookup_table['f1s_by_class'] = recall_by_class\n",
    "lookup_table.set_index('f1s_by_class')\n",
    "print(lookup_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, using these fused geojsons, you can visulaize the predictions by downloading the `/home/ubuntu/src/yolo_planes/yolov5/inference/class_one_out/bounding_boxes` folder to your local machine and using a geographic infromation system like QGIS and overlaying the bounding boxes onto the real image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Solaris",
   "language": "python",
   "name": "solaris"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
